{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Chatbot 代码学习\n",
    "代码来源：https://pytorch.org/tutorials/beginner/chatbot_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import pdb\n",
    "import math\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 打印数据文件，用于查看\n",
    "\n",
    "后面会多次用到这个函数来展示一些函数的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n",
      "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n'\n",
      "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\"\n",
      "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n'\n",
      "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n'\n",
      "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n'\n"
     ]
    }
   ],
   "source": [
    "corpus_name = \"cornell_movie-dialogs_corpus\"\n",
    "corpus = os.path.join(\"../data\", corpus_name)\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "printLines(os.path.join(corpus, \"movie_lines.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建格式化数据文件\n",
    "\n",
    "The following functions facilitate the parsing of the raw *movie_lines.txt* data file.\n",
    "以下函数用于解析*movie_lines.txt*中的每一行数据：\n",
    "\n",
    "- `loadLines` 分割一行，并存为字典格式 (lineID, characterID, movieID, character, text)\n",
    "- `loadConversations` 将*movie_conversations.txt*读取后，最后根据最后一列的LineId关联append具体的Line\n",
    "- `extractSentencePairs` 只抽取出句子对，不管其他信息, lineID, characterID, movieID, character 全不要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits each line of the file into a dictionary of fields  操作：\"movie_lines.txt\"\n",
    "def loadLines(fileName, fields):\n",
    "    lines = {}\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            lineObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                lineObj[field] = values[i]\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "    return lines\n",
    "\n",
    "\n",
    "# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\n",
    "def loadConversations(fileName, lines, fields):    \n",
    "    conversations = []\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f: \n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            convObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                convObj[field] = values[i]\n",
    "            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
    "            lineIds = eval(convObj[\"utteranceIDs\"])\n",
    "            # Reassemble lines\n",
    "            convObj[\"lines\"] = []\n",
    "            for lineId in lineIds:\n",
    "                convObj[\"lines\"].append(lines[lineId])\n",
    "            conversations.append(convObj)\n",
    "    return conversations\n",
    "\n",
    "\n",
    "# Extracts pairs of sentences from conversations\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                 qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "处理好数据，保存为一个新的数据文件 \"formatted_movie_lines.txt\" ，里面每行记录是两个句子，句子间用 \"\\t\" 间隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus...\n",
      "\n",
      "Loading conversations...\n",
      "\n",
      "Writing newly formatted file...\n",
      "\n",
      "Sample lines from file:\n",
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\r\\r\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\r\\r\\n\"\n",
      "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\r\\r\\n\"\n",
      "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\r\\r\\n\"\n",
      "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\r\\r\\n\"\n",
      "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\r\\r\\n\"\n",
      "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\r\\r\\n\"\n",
      "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\r\\r\\n'\n",
      "b\"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\tThat's a shame.\\r\\r\\n\"\n",
      "b'Gosh, if only we could find Kat a boyfriend...\\tLet me see what I can do.\\r\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "# Define path to new file\n",
    "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
    "\n",
    "delimiter = '\\t'\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# Initialize lines dict, conversations list, and field ids\n",
    "lines = {}\n",
    "conversations = []\n",
    "MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
    "MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "\n",
    "# Load lines and process conversations\n",
    "print(\"\\nProcessing corpus...\")\n",
    "lines = loadLines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\n",
    "print(\"\\nLoading conversations...\")\n",
    "conversations = loadConversations(os.path.join(corpus, \"movie_conversations.txt\"),\n",
    "                                  lines, MOVIE_CONVERSATIONS_FIELDS)\n",
    "\n",
    "# Write new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter)\n",
    "    for pair in extractSentencePairs(conversations):\n",
    "        writer.writerow(pair)\n",
    "\n",
    "# Print a sample of lines\n",
    "print(\"\\nSample lines from file:\")\n",
    "printLines(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 制作词汇表\n",
    "\n",
    "定义了一个 `Voc` 字典类，主要目的是：\n",
    "\n",
    "- 从词映射到词标，从词标映射到词\n",
    "- 计算每个单词的频次，计算所有单词的数量\n",
    "\n",
    "提供三种方法：\n",
    "\n",
    "- 将一个词加入字典中     （`addWord`）\n",
    "- 将一个句子中的所有词都加入字典中  (`addSentence`）\n",
    "- 删除（修剪）字典中的低频词  (`trim`) ，修剪后的字典词出现的频次都变为1，所以只能修剪一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # 句子填充符号，将短句子边长，保证所有句子等长\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 几个补充操作\n",
    "\n",
    "- 去除英文中的重音（accent）符号\n",
    "- 让符号和单词别连着，只保留三种符号 \".!?\"，栓出连续空格\n",
    "- 删除过长的对话，是直接删除，不是剪短"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 221282 sentence pairs\n",
      "Trimmed to 64271 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 18008\n",
      "\n",
      "pairs:\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):   # 删除重音符号\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)    #用空格间隔文本符号与单词，英文中句子的最后一个单词后面是没有空格的，接的是标点符号\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)   # 删除除三个文本符号\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()    #删除连续空格，只保留一个空格\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines if len(l.split('\\t'))>1]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    if not (isinstance(p,list) and len(p)>1): pdb.set_trace()\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除包含非常用词的句子对\n",
    "\n",
    "删除很少出现的词语（少见词）后，如果输入和输出都包含这些少见词，我们就这条训练记录删去，这样有利于模型的快速收敛，主要分为两个步骤：\n",
    "\n",
    "- 使用 `Voc` 字典类中的修剪方法（`voc.trim`），将词频小于 `MIN_COUNT`的单词删去\n",
    "- 如果一个句子对中两个句子均包含少见词，我们把这个句子中数据集合中删去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 7823 / 18005 = 0.4345\n",
      "Trimmed from 64271 pairs to 53165, 0.8272 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备真正的模型数据\n",
    "\n",
    "我们需要使用GPU加速模型，所以需要每次按照batch_size 传入数据，第n个时间步，我们传入的不是第n个句子，而是所有batch_size个句子的中的第n个词， 所以我们需要将传入的数据shape转置，从(batch_size,max_length) -->(max_length,batch_size)，所以我们定义了以下这些函数：\n",
    "\n",
    "每个batch的句子对分为input sentences 和 output sentence\n",
    "- `inputVar`: 把传入的一个batch的input sentences转为词标，并把每行填充到等长，记录每行的句子长度lengths，并转为torch.tensor格式\n",
    "\n",
    "- `outputVar` 实现了类似的功能，但是不同于`inputVar`返回句子长度lengths，这个功能返回的是同样shape的二进制矩阵mask来记录那些位置是非padding词，以此记录句子长度\n",
    "\n",
    "- `batch2TrainData` simply takes a bunch of pairs and returns the input and target tensors using the aforementioned functions.\n",
    "\n",
    "### 一些小技巧：\n",
    "\n",
    "`random.choice(seq)`: 方法返回一个列表，元组或字符串的随机项。\n",
    "\n",
    "`list.sort()`: pair_batch是一个list数据，pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "\n",
    "`itertools.zip_longest(a,b,.. fillvalue=fillvalue)`: 按照最长的序列的长度末尾填充短的list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[ 131,   50,  101,   50,  167],\n",
      "        [1859,    6,   37,  623,    4],\n",
      "        [   4,   50,   70,    6,    2],\n",
      "        [  76,   47, 1082,    2,    0],\n",
      "        [  37,    7,    4,    0,    0],\n",
      "        [  12,  260,    2,    0,    0],\n",
      "        [3078,    6,    0,    0,    0],\n",
      "        [   4,    2,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "lengths: tensor([9, 8, 6, 4, 3])\n",
      "target_variable: tensor([[  12,   92,   62,   53,  115],\n",
      "        [3078,    7,  519,  574,   36],\n",
      "        [   6, 4294, 2000,  623,   38],\n",
      "        [   2,  169,   76,    4,    7],\n",
      "        [   0,  208,    4,    2,    8],\n",
      "        [   0, 2411,    2,    0,   40],\n",
      "        [   0,    6,    0,    0,   41],\n",
      "        [   0,    2,    0,    0,    6],\n",
      "        [   0,    0,    0,    0,    2]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1]], dtype=torch.uint8)\n",
      "max_target_len: 9\n"
     ]
    }
   ],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])  # 记录每一行的词数，变为tensor格式\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)    # 以Question字符数量从多到少排序\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现编码器\n",
    "\n",
    "参考：https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-custom-nn-modules\n",
    "\n",
    "- 继承nn.Module类\n",
    "\n",
    "- 重构函数forward 以获得输入张量和得到输出结果\n",
    "\n",
    "说明：我们只需要定义网络模型前向过程的结构，后向的梯度传播已经有`torch.autograd`实现，不需要我们定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "加入了注意力机制的Decoder，教程提到的两种注意力机制：BahdanauAttention与LuongAttention的详细介绍参考下面链接：\n",
    "\n",
    "[BahdanauAttention与LuongAttention注意力机制简介](https://blog.csdn.net/u010960155/article/details/82853632)\n",
    "\n",
    "这里提到的三种方法：\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "是LuongAttention中的三种对齐函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型的loss\n",
    "\n",
    "`torch.view`：就是numpy.reshape\n",
    "\n",
    "`torch.gather(input, dim, index, out=None)`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "\n",
    "使用两个训练技巧帮助模型收敛：\n",
    "\n",
    "- `teacher forcing`：在训练时，以一定的概率(teacher_forcing_ratio)使用当前目标词作为解码器的下一个输入，而不是使用解码器的当前猜测词，\n",
    "值得注意的是，使用目标词来训练解码很容易造成模型不问的那个 ，所以要设置合适的概率值\n",
    "\n",
    "- `gradient clipping`：称为梯度裁剪，是用于解决梯度爆炸问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 定义评估器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
